{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(repr)\n",
    "library(reshape2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "First we check how much does feature selection affect the final results.\n",
    "As with MLP we are obligued to do a feature selection, we need to compare\n",
    "to see if there is a possible inconsistency later.\n",
    "\n",
    "For this we need the results of handcrafted features with and without\n",
    "feature selection for the classifiers:\n",
    "+ Decision Tree\n",
    "+ Logistic Regression\n",
    "+ Naive Bayes\n",
    "+ SVM\n",
    "\n",
    "We collect the metrics following metrics both considering monoclass\n",
    "lemmas and filtering them:\n",
    "+ Accuracy\n",
    "+ Macro Precision\n",
    "+ Macro Recall\n",
    "\n",
    "After that we also collect the Cohen's kappa score for each classifiers\n",
    "vs the ground truth. But only for the cases of lemmas with more than one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp.df <- read.csv('./data/handcrafted_vs_feature_selection.csv')\n",
    "exp.df.nomono <- exp.df[exp.df$num_classes > 1,]\n",
    "\n",
    "exp.df.metrics <- melt(exp.df, id.vars = c('classifier', 'representation', 'lemma', 'corpus'),\n",
    "                       measure.vars = c('accuracy', 'macro_precision', 'macro_recall'))\n",
    "exp.df.metrics.nomono <- melt(exp.df.nomono, id.vars = c('classifier', 'representation', 'lemma', 'corpus'),\n",
    "                              measure.vars = c('accuracy', 'macro_precision', 'macro_recall'))\n",
    "exp.df.kappa <- melt(exp.df.nomono, id.vars = c('classifier', 'representation', 'lemma', 'corpus'),\n",
    "                     measure.vars = c('kappa_score'))\n",
    "exp.df.kappa <- exp.df.kappa[(exp.df.kappa$corpus == 'sensem.test') | (exp.df.kappa$corpus == 'semeval.test'),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base metrics comparing features for all lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels(exp.df.metrics$representation) <- c('All Handcrafted Features', 'Top 10000 Handcrafted Features')\n",
    "levels(exp.df.metrics$corpus) <- c('Semeval Test Set', 'Semeval Train Set', 'SenSem Test Set', 'SenSem Train Set')\n",
    "exp.df.metrics$corpus <- factor(exp.df.metrics$corpus, levels = rev(levels(exp.df.metrics$corpus)))\n",
    "levels(exp.df.metrics$variable) <- c('Accuracy', 'Precision\\nMacro Average', 'Recall\\nMacro Average')\n",
    "levels(exp.df.metrics$classifier) <- c('Decision Tree', 'Logistic Regression', 'Naive Bayes', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=8)\n",
    "\n",
    "g <- ggplot(exp.df.metrics, aes(x = variable, y = value, fill = corpus))\n",
    "g <- g + geom_boxplot() + stat_boxplot(geom = 'errorbar')\n",
    "g <- g + facet_grid(classifier ~ representation)\n",
    "g <- g + theme(legend.position = 'bottom', legend.title = element_blank(),\n",
    "               axis.title.x = element_blank(), axis.title.y = element_blank())\n",
    "ggsave('./plots/handcrafted_vs_feature_selection_metrics.png', plot = g, width = 8, height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base metrics comparing features for lemmas with more than 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels(exp.df.metrics.nomono$representation) <- c('All Handcrafted Features', 'Top 10000 Handcrafted Features')\n",
    "levels(exp.df.metrics.nomono$corpus) <- c('Semeval Test Set', 'Semeval Train Set', 'SenSem Test Set',\n",
    "                                          'SenSem Train Set')\n",
    "exp.df.metrics.nomono$corpus <- factor(exp.df.metrics.nomono$corpus,\n",
    "                                       levels = rev(levels(exp.df.metrics.nomono$corpus)))\n",
    "levels(exp.df.metrics.nomono$variable) <- c('Accuracy', 'Precision\\nMacro Average', 'Recall\\nMacro Average')\n",
    "levels(exp.df.metrics.nomono$classifier) <- c('Decision Tree', 'Logistic Regression', 'Naive Bayes', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=8)\n",
    "\n",
    "g <- ggplot(exp.df.metrics.nomono, aes(x = variable, y = value, fill = corpus))\n",
    "g <- g + geom_boxplot() + stat_boxplot(geom = 'errorbar')\n",
    "g <- g + facet_grid(classifier ~ representation)\n",
    "g <- g + theme(legend.position = 'bottom', legend.title = element_blank(),\n",
    "               axis.title.x = element_blank(), axis.title.y = element_blank())\n",
    "ggsave('./plots/handcrafted_vs_feature_selection_metrics_no_monoclass.png', plot = g, width = 8, height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kappa comparing features for lemmas with more than one sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels(exp.df.kappa$representation) <- c('All Handcrafted Features', 'Top 10000 Handcrafted Features')\n",
    "levels(exp.df.kappa$corpus) <- c('Semeval Test Set', 'Semeval Train Set', 'SenSem Test Set', 'SenSem Train Set')\n",
    "exp.df.kappa$corpus <- factor(exp.df.kappa$corpus, levels = rev(levels(exp.df.kappa$corpus)))\n",
    "levels(exp.df.kappa$variable) <- c('Cohen\\'s Kappa Score\\nvs. Ground Truth')\n",
    "levels(exp.df.kappa$classifier) <- c('Decision Tree', 'Logistic Regression', 'Naive Bayes', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=8)\n",
    "\n",
    "g <- ggplot(exp.df.kappa, aes(x = variable, y = value, fill = corpus))\n",
    "g <- g + geom_boxplot() + stat_boxplot(geom = 'errorbar')\n",
    "g <- g + facet_grid(classifier ~ representation)\n",
    "g <- g + theme(legend.position = 'bottom', legend.title = element_blank(),\n",
    "               axis.title.x = element_blank(), axis.title.y = element_blank())\n",
    "g <- g + ylim(c(-1.0, 1.0))\n",
    "ggsave('./plots/handcrafted_vs_feature_selection_kappa.png', plot = g, width = 8, height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representations\n",
    "\n",
    "After finding out there is no difference using Feature Selection, we show the general metrics\n",
    "results for all the classifiers, that is:\n",
    "+ Baseline\n",
    "+ Decision Tree\n",
    "+ Logistic Regression\n",
    "+ MLP\n",
    "+ Naive Bayes\n",
    "+ SVM\n",
    "\n",
    "For this we use the following representations:\n",
    "+ Feature selection of handcrafted features\n",
    "+ Hashed features with only positive values\n",
    "+ Hashed features with positive and negative values (not valid with Naive Bayes)\n",
    "\n",
    "The first boxplot will have the representations as columns and the classifiers as rows\n",
    "with the following metrics:\n",
    "+ Accuracy\n",
    "+ Macro Precision\n",
    "+ Macro Recall\n",
    "+ PMFC\n",
    "+ RMLFC\n",
    "\n",
    "This last will show which is the best representation (or if there is any difference at all) and\n",
    "then we use the visual information to select such representation and also we discard those\n",
    "algorithms which are visually showing less performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp.df <- read.csv('./data/experiment0_general_metrics.csv')\n",
    "exp.df.nomono <- exp.df[exp.df$num_classes > 1,]\n",
    "\n",
    "exp.df.metrics <- melt(exp.df, id.vars = c('classifier', 'representation', 'lemma', 'corpus'),\n",
    "                       measure.vars = c('accuracy', 'macro_precision', 'macro_recall', 'pmfc', 'rmlfc'))\n",
    "exp.df.metrics.nomono <- melt(exp.df.nomono, id.vars = c('classifier', 'representation', 'lemma', 'corpus'),\n",
    "                              measure.vars = c('accuracy', 'macro_precision', 'macro_recall', 'pmfc', 'rmlfc'))\n",
    "exp.df.kappa <- melt(exp.df.nomono, id.vars = c('classifier', 'representation', 'lemma', 'corpus'),\n",
    "                     measure.vars = c('kappa_score'))\n",
    "exp.df.kappa <- exp.df.kappa[(exp.df.kappa$corpus == 'sensem.test') | (exp.df.kappa$corpus == 'semeval.test'),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base metrics comparing representations for all lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels(exp.df.metrics$representation) <- c('Top 10000 Handcrafted Features', 'Hashing with All Positive Features',\n",
    "                                           'Hashing with Negative Features')\n",
    "levels(exp.df.metrics$corpus) <- c('Semeval Test Set', 'Semeval Train Set', 'SenSem Test Set', 'SenSem Train Set')\n",
    "exp.df.metrics$corpus <- factor(exp.df.metrics$corpus, levels = rev(levels(exp.df.metrics$corpus)))\n",
    "levels(exp.df.metrics$variable) <- c('Accuracy', 'Precision\\nMacro Average', 'Recall\\nMacro Average',\n",
    "                                     'PMFC', 'RMLFC')\n",
    "levels(exp.df.metrics$classifier) <- c('Baseline', 'Decision Tree', 'Logistic\\nRegression',\n",
    "                                       'MLP', 'Naive Bayes', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=9, repr.plot.height=8)\n",
    "\n",
    "g <- ggplot(exp.df.metrics, aes(x = variable, y = value, fill = corpus))\n",
    "g <- g + geom_boxplot() + stat_boxplot(geom = 'errorbar')\n",
    "g <- g + facet_grid(classifier ~ representation)\n",
    "g <- g + theme(legend.position = 'bottom', legend.title = element_blank(),\n",
    "               axis.title.x = element_blank(), axis.title.y = element_blank(),\n",
    "               axis.text.x=element_text(angle=45, vjust=0.5))\n",
    "ggsave('./plots/experiment0_representations_comparison.png', plot = g, width = 9, height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base metrics comparing features for lemmas with more than 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels(exp.df.metrics.nomono$representation) <- c('Top 10000 Handcrafted Features',\n",
    "                                                  'Hashing with All Positive Features',\n",
    "                                                  'Hashing with Negative Features')\n",
    "levels(exp.df.metrics.nomono$corpus) <- c('Semeval Test Set', 'Semeval Train Set', 'SenSem Test Set',\n",
    "                                          'SenSem Train Set')\n",
    "exp.df.metrics.nomono$corpus <- factor(exp.df.metrics.nomono$corpus,\n",
    "                                       levels = rev(levels(exp.df.metrics.nomono$corpus)))\n",
    "levels(exp.df.metrics.nomono$variable) <- c('Accuracy', 'Precision\\nMacro Average', 'Recall\\nMacro Average',\n",
    "                                            'PMFC', 'RMLFC')\n",
    "levels(exp.df.metrics.nomono$classifier) <- c('Baseline', 'Decision Tree', 'Logistic\\nRegression',\n",
    "                                              'MLP', 'Naive Bayes', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=9, repr.plot.height=8)\n",
    "\n",
    "g <- ggplot(exp.df.metrics.nomono, aes(x = variable, y = value, fill = corpus))\n",
    "g <- g + geom_boxplot() + stat_boxplot(geom = 'errorbar')\n",
    "g <- g + facet_grid(classifier ~ representation)\n",
    "g <- g + theme(legend.position = 'bottom', legend.title = element_blank(),\n",
    "               axis.title.x = element_blank(), axis.title.y = element_blank(),\n",
    "               axis.text.x=element_text(angle=45, vjust=0.5))\n",
    "ggsave('./plots/experiment0_representations_comparison_no_monoclass.png', plot = g, width = 9, height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kappa comparing features for lemmas with more than one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels(exp.df.kappa$representation) <- c('Top 10000 Handcrafted Features', 'Hashing with All Positive Features',\n",
    "                                         'Hashing with Negative Features')\n",
    "levels(exp.df.kappa$corpus) <- c('Semeval Test Set', 'Semeval Train Set', 'SenSem Test Set', 'SenSem Train Set')\n",
    "exp.df.kappa$corpus <- factor(exp.df.kappa$corpus, levels = rev(levels(exp.df.kappa$corpus)))\n",
    "levels(exp.df.kappa$variable) <- c('Cohen\\'s Kappa Score\\nvs. Ground Truth')\n",
    "levels(exp.df.kappa$classifier) <- c('Baseline', 'Decision Tree', 'Logistic\\nRegression',\n",
    "                                     'MLP', 'Naive Bayes', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=9, repr.plot.height=8)\n",
    "\n",
    "g <- ggplot(exp.df.kappa, aes(x = variable, y = value, fill = corpus))\n",
    "g <- g + geom_boxplot() + stat_boxplot(geom = 'errorbar')\n",
    "g <- g + facet_grid(classifier ~ representation)\n",
    "g <- g + theme(legend.position = 'bottom', legend.title = element_blank(),\n",
    "               axis.title.x = element_blank(), axis.title.y = element_blank())\n",
    "g <- g + ylim(c(-1.0, 1.0))\n",
    "ggsave('./plots/experiment0_kappa_representations_comparison.png', plot = g, width = 9, height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation selection and classifiers comparison\n",
    "\n",
    "Once compared the representations, we see if any of them is visually better than the others. If\n",
    "no representation shows real improvement, we decide to go with the one that simplifies everything (for now)\n",
    "that is Hashed All Positive Features.\n",
    "\n",
    "After selecting the final representation we need to do a classifier comparison to select the classifiers\n",
    "to work with. Previous to this we filter out those classifiers that show visually worse performance\n",
    "in the previous plots (baseline and naive_bayes).\n",
    "\n",
    "This is done using two graphics:\n",
    "+ A boxplot showing the different metrics of each classifier side by side.\n",
    "+ A heatmap showing the kappa average values comparando cada clasificador contra todos los demÃ¡s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_representation <- 'hashed'\n",
    "\n",
    "exp.df <- read.csv('./data/experiment0_general_metrics.csv')\n",
    "exp.df <- exp.df[exp.df$representation == selected_representation,]\n",
    "exp.df <- exp.df[(exp.df$classifier != 'baseline') & (exp.df$classifier != 'naive_bayes'),]\n",
    "exp.df.nomono <- exp.df[exp.df$num_classes > 1,]\n",
    "exp.df.kappa.heatmap <- read.csv('./data/experiment0_kappa_interclassifier.csv')\n",
    "\n",
    "exp.df.metrics <- melt(exp.df, id.vars = c('classifier', 'lemma', 'corpus'),\n",
    "                       measure.vars = c('accuracy', 'macro_precision', 'macro_recall', 'pmfc', 'rmlfc'))\n",
    "exp.df.metrics.nomono <- melt(exp.df.nomono, id.vars = c('classifier', 'lemma', 'corpus'),\n",
    "                              measure.vars = c('accuracy', 'macro_precision', 'macro_recall', 'pmfc', 'rmlfc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers comparison for all lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "levels(exp.df.metrics$corpus) <- c('Semeval Test Set', 'Semeval Train Set', 'SenSem Test Set', 'SenSem Train Set')\n",
    "exp.df.metrics$corpus <- factor(exp.df.metrics$corpus, levels = rev(levels(exp.df.metrics$corpus)))\n",
    "levels(exp.df.metrics$variable) <- c('Accuracy', 'Precision\\nMacro Average', 'Recall\\nMacro Average',\n",
    "                                     'PMFC', 'RMLFC')\n",
    "levels(exp.df.metrics$classifier) <- c('Baseline', 'Decision Tree', 'Logistic Regression', 'MLP',\n",
    "                                       'Naive Bayes', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=3.5)\n",
    "\n",
    "g <- ggplot(exp.df.metrics, aes(x = variable, y = value, fill = corpus))\n",
    "g <- g + geom_boxplot() + stat_boxplot(geom = 'errorbar')\n",
    "g <- g + facet_wrap(~ classifier, nrow = 1)\n",
    "g <- g + theme(legend.position = 'bottom', legend.title = element_blank(),\n",
    "               axis.title.x = element_blank(), axis.title.y = element_blank(),\n",
    "               axis.text.x = element_text(angle=45, vjust=0.5))\n",
    "ggsave('./plots/experiment0_classifiers_comparison.png', plot = g, width = 8, height = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers comparison for lemmas with more than 1 sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "levels(exp.df.metrics.nomono$corpus) <- c('Semeval Test Set', 'Semeval Train Set', 'SenSem Test Set',\n",
    "                                          'SenSem Train Set')\n",
    "exp.df.metrics.nomono$corpus <- factor(exp.df.metrics.nomono$corpus,\n",
    "                                       levels = rev(levels(exp.df.metrics.nomono$corpus)))\n",
    "levels(exp.df.metrics.nomono$variable) <- c('Accuracy', 'Precision\\nMacro Average', 'Recall\\nMacro Average',\n",
    "                                            'PMFC', 'RMLFC')\n",
    "levels(exp.df.metrics.nomono$classifier) <- c('Baseline', 'Decision Tree', 'Logistic Regression', 'MLP',\n",
    "                                              'Naive Bayes', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=3.5)\n",
    "\n",
    "g <- ggplot(exp.df.metrics.nomono, aes(x = variable, y = value, fill = corpus))\n",
    "g <- g + geom_boxplot() + stat_boxplot(geom = 'errorbar')\n",
    "g <- g + facet_wrap(~ classifier, nrow = 1)\n",
    "g <- g + theme(legend.position = 'bottom', legend.title = element_blank(),\n",
    "               axis.title.x = element_blank(), axis.title.y = element_blank(),\n",
    "               axis.text.x=element_text(angle=45, vjust=0.5))\n",
    "ggsave('./plots/experiment0_classifiers_comparison_no_monoclass.png', plot = g, width = 8, height = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Kappa inter-classifier heatmap for lemmas with more than one sense for hashed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels(exp.df.kappa.heatmap$corpus) <- c('Semeval', 'SenSem')\n",
    "exp.df.kappa.heatmap$corpus <- factor(exp.df.kappa.heatmap$corpus,\n",
    "                                      levels = rev(levels(exp.df.kappa.heatmap$corpus)))\n",
    "exp.df.kappa.heatmap$t1 <- factor(exp.df.kappa.heatmap$t1,\n",
    "                                  levels = c('ground_truth', 'decision_tree', 'log', 'mlp_5000', 'svm'))\n",
    "levels(exp.df.kappa.heatmap$t1) <- c('Ground\\nTruth', 'Decision\\nTree', 'Logistic\\nRegression', 'MLP', 'SVM')\n",
    "exp.df.kappa.heatmap$t2 <- factor(exp.df.kappa.heatmap$t2,\n",
    "                                  levels = c('ground_truth', 'decision_tree', 'log', 'mlp_5000', 'svm'))\n",
    "levels(exp.df.kappa.heatmap$t2) <- c('Ground\\nTruth', 'Decision\\nTree', 'Logistic\\nRegression', 'MLP', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "\n",
    "g <- ggplot(exp.df.kappa.heatmap, aes(x = t1, y = t2))\n",
    "g <- g + geom_tile(aes(fill = kappa_score), colour = \"white\")\n",
    "g <- g + geom_text(aes(label = round(kappa_score, 2)), colour = \"white\", size = 3.5)\n",
    "g <- g + scale_fill_gradient(low=\"steelblue\", high=\"black\", name=\"Kappa Score\")\n",
    "g <- g + facet_grid(~ corpus)\n",
    "g <- g + ylim(rev(levels(exp.df.kappa.heatmap$t2)))\n",
    "g <- g + theme(legend.position='none',\n",
    "               axis.title.x = element_blank(), axis.title.y = element_blank(),\n",
    "               axis.text.y = element_text(hjust=0.5))\n",
    "g <- g + labs(x=\"Classifier\")\n",
    "ggsave('./plots/experiment0_interclassifier_kappa.png', plot = g, width = 8, height = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R [conda env:python3]",
   "language": "R",
   "name": "conda-env-python3-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
